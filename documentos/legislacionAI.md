# Ley de inteligencia artificial - UniÃ³n Europea

> Fuente: [LuizaJarovsky@X](https://twitter.com/LuizaJarovsky/status/1767899302930657704)

El Parlamento Europeo acaba de aprobar la Ley de Inteligencia Artificial. 

Esto es lo que todos deberÃ­an saber:

La Ley de Inteligencia Artificial sigue un enfoque basado en el riesgo. Algunos sistemas de IA estÃ¡n prohibidos, como los que implican:

- **ManipulaciÃ³n cognitiva** del comportamiento de personas o grupos vulnerables especÃ­ficos;
- **PuntuaciÃ³n social**: clasificar a las personas segÃºn su comportamiento, estatus socioeconÃ³mico o caracterÃ­sticas personales; ([ðŸ“º](https://es.wikipedia.org/wiki/Nosedive))
- **IdentificaciÃ³n** biomÃ©trica y **categorizaciÃ³n** de personas;
- **Sistemas de identificaciÃ³n biomÃ©trica en tiempo real y a distancia**, como el reconocimiento facial.([âœˆï¸](https://www.aena.es/es/pasajeros/equipajes-controles/reconocimiento-facial-aeropuertos.html))

âžµ Algunos sistemas de IA caen en la categorÃ­a de "alto riesgo", como aquellos que implican:

- Infraestructuras crÃ­ticas (por ejemplo, transporte) que podrÃ­an poner en peligro la vida y la salud de los ciudadanos;
- EducaciÃ³n o formaciÃ³n profesional que pueden determinar el acceso a la educaciÃ³n y la carrera profesional de alguien (por ejemplo, puntuaciÃ³n de exÃ¡menes);
- Componentes de seguridad de productos (por ejemplo, aplicaciÃ³n de IA en cirugÃ­a asistida por robots);
- Empleo, gestiÃ³n de trabajadores y acceso al autoempleo (por ejemplo, software de clasificaciÃ³n de CV para procedimientos de contrataciÃ³n);
- Servicios privados y pÃºblicos esenciales (por ejemplo, puntuaciÃ³n crediticia que niega a los ciudadanos la oportunidad de obtener un prÃ©stamo);
- AplicaciÃ³n de la ley que puede interferir con los derechos fundamentales de las personas (por ejemplo, evaluaciÃ³n de la fiabilidad de las pruebas);
- GestiÃ³n de migraciÃ³n, asilo y control fronterizo (por ejemplo, examen automatizado de solicitudes de visa);
- AdministraciÃ³n de justicia y procesos democrÃ¡ticos (por ejemplo, soluciones de IA para buscar sentencias judiciales).

âžµ Los sistemas de IA de alto riesgo serÃ¡n evaluados antes de salir al mercado y tambiÃ©n durante todo su ciclo de vida. Las personas tendrÃ¡n derecho a presentar quejas sobre los sistemas de IA a las autoridades nacionales designadas.

âžµ **La IA generativa, como ChatGPT, no serÃ¡ clasificada como de alto riesgo**, pero deberÃ¡ cumplir con los requisitos de transparencia y la ley de derechos de autor de la UE. Algunas de las obligaciones son:

- Revelar que el contenido fue generado por IA;
- DiseÃ±ar el modelo para evitar que genere contenido ilegal;
- Publicar resÃºmenes de datos con derechos de autor utilizados para el entrenamiento.

âžµ Se espera que la Ley de Inteligencia Artificial entre en vigor oficialmente en mayo o junio, y sus disposiciones comenzarÃ¡n a aplicarse en etapas:

- 6 meses despuÃ©s: los paÃ­ses deberÃ¡n prohibir los sistemas de IA prohibidos;
- 1 aÃ±o despuÃ©s: comenzarÃ¡n a aplicarse las reglas para los sistemas de IA de propÃ³sito general;
- 2 aÃ±os despuÃ©s: toda la Ley de IA serÃ¡ aplicable.

âžµ Las multas por incumplimiento pueden llegar hasta 35 millones de euros o el 7% del volumen de negocios anual mundial.

> Recomendado: [Luiza's newsletter](https://www.luizasnewsletter.com/)
