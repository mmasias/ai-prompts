<div align=right>

|[![](https://img.shields.io/badge/-Inicio-FFF?style=flat&logo=Emlakjet&logoColor=black)](/README.md) [![](https://img.shields.io/badge/-Introducci칩n-FFF?style=flat&logo=abbrobotstudio&logoColor=black)](/documentos/intro.md) [![](https://img.shields.io/badge/-Modelos_de_lenguaje-FFF?style=flat&logo=LiveChat&logoColor=black)](/documentos/LLMs.md) [![](https://img.shields.io/badge/-Panor치mica-FFF?style=flat&logo=openstreetmap&logoColor=black)](/documentos/panoramica.md)<br>  [![](https://img.shields.io/badge/-Prompts-FFF?style=flat&logo=Proton&logoColor=black)](/documentos/prompts/README.md) [![](https://img.shields.io/badge/-Ing,_de_prompts-FFF?style=flat&logo=googleearthengine&logoColor=black)](/documentos/ingenieriaDePrompts/README.md) [![](https://img.shields.io/badge/-Patrones-FFF?style=flat&logo=textpattern&logoColor=black)](/documentos/ingenieriaDePrompts/patrones/README.md) [![](https://img.shields.io/badge/-Casos_de_uso-FFF?style=flat&logo=gitbook&logoColor=black)](/documentos/casosDeUso/README.md)|
|-:|

</div>

# Ventana de contexto

## 쯇or qu칠?

Los modelos de lenguaje de gran escala no tienen una "memoria" en el sentido tradicional, es decir que no almacenan informaci칩n de conversaciones pasadas o de instrucciones previas. Por lo tanto, la ventana de contexto es la 칰nica "vista" que el modelo tiene sobre la conversaci칩n en curso.

## 쯈u칠?

La "Ventana de contexto" es un fragmento de texto que incluye las interacciones m치s recientes en una conversaci칩n con el modelo. Este fragmento es lo que el modelo utiliza para generar respuestas. 

<div align=center>
  
|Contexto|***PROMPT***|Respuesta|
|-|-|-|

</div>

En el caso de GPT-3 y GPT-4, [la ventana de contexto tiene un l칤mite de tokens](https://platform.openai.com/docs/models/gpt-3-5), que son las unidades b치sicas de texto que el modelo puede entender.

<div align=center>

||Ventana de contexto<br>(*en tokens*)|
|-|:-:|
GPT-3|2049
GPT-3.5|4096
GPT-4| 8192<br>*32768 (?)*

</div>

Si una conversaci칩n supera este l칤mite, se deben eliminar partes del texto para que quepa en la ventana de contexto.

### Tokens vs palabras

|Tokens vs palabras|
|-|
[@ChatGPT4](https://chat.openai.com/share/52db2723-48e5-49f1-a734-67b721920bf1)
[@ChatGPT3.5](https://chat.openai.com/share/b10b28f2-2b4c-4ccc-abe8-dd130e4b6990)
[@Copilot](https://sl.bing.net/oiXW58tqDY)

Los modelos de lenguaje no "ven" palabras, sino tokens.

|Frase|Frase tokenizada|
|-|-|
|Learning new things is fun!|Learning / new / things / is / fun / !|
|Prompting is a new powerful developer tool.|Prom / pt / ing / is / a / new / powerful / developer / tool / .|
|lollipop|l / oll / ipop|

Para el idioma ingl칠s, 1 token es alrededor de 4 caracteres

> [Hablando de tokens](tokens.md)

## 쯇ara qu칠?

|||
|-|-|
Coherencia|Ayuda al modelo a mantener la coherencia en una conversaci칩n al tener en cuenta las interacciones previas.
Contextualizaci칩n|Permite que el modelo entienda preguntas o declaraciones que requieren conocimiento de declaraciones previas.
Personalizaci칩n Temporal|Aunque el modelo no tiene memoria persistente, la ventana de contexto permite una forma de "personalizaci칩n" durante la duraci칩n de la conversaci칩n.

## 쮺칩mo?

Cuando se interact칰a con un modelo como ChatGPT, cada entrada (pregunta, comentario, etc.) se a침ade a la ventana de contexto existente junto con la respuesta del modelo. Este contexto acumulado se utiliza para generar respuestas a futuras entradas.

Si se alcanza el l칤mite de tokens, se recorta el texto m치s antiguo para hacer espacio para la nueva interacci칩n.

## 쮺u치nto?

Un token en GPT-3 o GPT-4 puede ser tan peque침o como un solo car치cter o tan grande como una palabra completa. Por ejemplo, "ChatGPT es genial" se descompondr칤a en algo como ["Chat", "G", "PT", " es", " genial"], lo que sumar칤a 5 tokens.

Entonces, los tokens mencionados anteriormente equivaldr칤an, aproximadamente a:

||4096<br>GPT-3.5|8192<br>GPT-4|32768<br>GPT-4|
|-|:-:|:-:|:-:|
P치ginas de texto en Word<br>*(con tama침o de fuente est치ndar y m치rgenes normales)*|8-10|16-20|65-80
Palabras|3500-4000|7000-8000|28000-32000
Tweets<br>*considerando que un tweet tiene un l칤mite de 280 caracteres*|15-20|30-40|120-160
[游늬](https://drive.google.com/drive/folders/1sHecgUKJyLfwhFBehn15R5bIXQTJ_sgs?usp=sharing) ***Pruebas de stress***|[游땻](https://chat.openai.com/share/6a42b7fd-59b4-475c-a818-af69c0fc5c61) <br/> [游땻游땻](https://chat.openai.com/share/e43be7f4-3e87-4ddd-800d-7606996eb203) <br/> [游땻游땻游땻](https://chat.openai.com/share/4396fda0-fe7f-43fc-8a43-28dc9e9d7d21) <br/> [游땻游땻游땻游땻](https://chat.openai.com/share/35492bb2-4252-4ab3-880c-b8792386ac51)|[游땻](https://chat.openai.com/share/b5fbcb0a-f57e-472f-99c6-8b831fbfb870)<br><br><br>[游땻游땻游땻游땻](https://chat.openai.com/share/88efa50b-4c05-40b0-9c83-da7d6f477650)
|||*consciente* de limitaciones?
