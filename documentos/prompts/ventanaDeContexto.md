<div align=right>

|[![](https://img.shields.io/badge/-Inicio-FFF?style=flat&logo=Emlakjet&logoColor=black)](/README.md) [![](https://img.shields.io/badge/-Introducci칩n-FFF?style=flat&logo=abbrobotstudio&logoColor=black)](/documentos/intro.md) [![](https://img.shields.io/badge/-Panor치mica-FFF?style=flat&logo=openstreetmap&logoColor=black)](/documentos/panoramica.md)[![](https://img.shields.io/badge/-Modelos_de_lenguaje-FFF?style=flat&logo=LiveChat&logoColor=black)](/documentos/LLMs.md)<br>  [![](https://img.shields.io/badge/-Prompts-FFF?style=flat&logo=Proton&logoColor=black)](/documentos/prompts/README.md) [![](https://img.shields.io/badge/-Ing,_de_prompts-FFF?style=flat&logo=googleearthengine&logoColor=black)](/documentos/ingenieriaDePrompts/README.md) [![](https://img.shields.io/badge/-Patrones-FFF?style=flat&logo=textpattern&logoColor=black)](/documentos/ingenieriaDePrompts/patrones/README.md) [![](https://img.shields.io/badge/8vP-FFF?style=flat&logo=v8&logoColor=black)](/documentos/prompts/mejoresPracticas/8virtudesDelPrompting.md) [![](https://img.shields.io/badge/-Casos_de_uso-FFF?style=flat&logo=gitbook&logoColor=black)](/documentos/casosDeUso/README.md)|
|-:|

</div>

# Ventana de contexto

## 쯇or qu칠?

Los modelos de lenguaje de gran escala no tienen una "memoria" en el sentido tradicional, es decir que no almacenan informaci칩n de conversaciones pasadas o de instrucciones previas. Por lo tanto, la ventana de contexto es la 칰nica "vista" que el modelo tiene sobre la conversaci칩n en curso.

## 쯈u칠?

La "Ventana de contexto" es un fragmento de texto que incluye las interacciones m치s recientes en una conversaci칩n con el modelo. Este fragmento es lo que el modelo utiliza para generar respuestas. 

<div align=center>
  
|Contexto|***PROMPT***|Respuesta|
|-|-|-|

</div>

En todos los modelos de lenguaje, [la ventana de contexto tiene un l칤mite](https://platform.openai.com/docs/models) medido en [tokens](tokens.md), que son las unidades b치sicas de texto que el modelo puede entender.

<div align=center>

### Modelos actuales (2024-2025)

||Ventana de contexto<br>(*en tokens*)|
|-|:-:|
|**OpenAI**||
|GPT-4o|128K
|GPT-4 Turbo|128K
|o1|200K
|**Anthropic**||
|Claude 3.5 Sonnet|200K
|Claude Sonnet 4.5|200K
|Claude 3 Opus|200K
|**Google**||
|Gemini 1.5 Pro|2M
|Gemini 1.5 Flash|1M
|**Meta**||
|Llama 3.1 (405B)|128K

<details>
<summary><i>Modelos anteriores (hist칩rico)</i></summary>

||Ventana de contexto<br>(*en tokens*)|
|-|:-:|
GPT-4 (8K)|8192
GPT-4 (32K)|32768
GPT-3.5|4096
GPT-3|2049

</details>

</div>

Si una conversaci칩n supera este l칤mite, se deben eliminar partes del texto para que quepa en la ventana de contexto.

> **Nota sobre la evoluci칩n:** La ventana de contexto ha crecido exponencialmente desde los primeros modelos. Lo que antes requer칤a t칠cnicas complejas de gesti칩n de contexto (resumir, fragmentar, olvidar), ahora es manejable directamente en modelos como Gemini 1.5 Pro (2M tokens). Sin embargo, las mejores pr치cticas de prompting siguen siendo relevantes: m치s contexto no significa necesariamente mejores resultados si el prompt no es claro, concreto y conciso.

### Tokens vs palabras

|Tokens vs palabras|
|-|
[@ChatGPT4](https://chat.openai.com/share/52db2723-48e5-49f1-a734-67b721920bf1)
[@ChatGPT3.5](https://chat.openai.com/share/b10b28f2-2b4c-4ccc-abe8-dd130e4b6990)
[@Copilot](https://sl.bing.net/oiXW58tqDY)

Los modelos de lenguaje no "ven" palabras, sino tokens.

|Frase|Frase tokenizada|
|-|-|
|Learning new things is fun!|Learning / new / things / is / fun / !|
|Prompting is a new powerful developer tool.|Prom / pt / ing / is / a / new / powerful / developer / tool / .|
|lollipop|l / oll / ipop|

Para el idioma ingl칠s, 1 token es alrededor de 4 caracteres

> [Hablando de tokens](tokens.md)

## 쯇ara qu칠?

|||
|-|-|
Coherencia|Ayuda al modelo a mantener la coherencia en una conversaci칩n al tener en cuenta las interacciones previas.
Contextualizaci칩n|Permite que el modelo entienda preguntas o declaraciones que requieren conocimiento de declaraciones previas.
Personalizaci칩n Temporal|Aunque el modelo no tiene memoria persistente, la ventana de contexto permite una forma de "personalizaci칩n" durante la duraci칩n de la conversaci칩n.

## 쮺칩mo?

Cuando se interact칰a con un modelo como ChatGPT, cada entrada (pregunta, comentario, etc.) se a침ade a la ventana de contexto existente junto con la respuesta del modelo. Este contexto acumulado se utiliza para generar respuestas a futuras entradas.

Si se alcanza el l칤mite de tokens, se recorta el texto m치s antiguo para hacer espacio para la nueva interacci칩n.

## 쮺u치nto?

Un token en los modelos de lenguaje puede ser tan peque침o como un solo car치cter o tan grande como una palabra completa. Por ejemplo, "ChatGPT es genial" se descompondr칤a en algo como ["Chat", "G", "PT", " es", " genial"], lo que sumar칤a 5 tokens. La tokenizaci칩n var칤a ligeramente entre modelos (GPT, Claude, Gemini, Llama), pero el concepto fundamental es el mismo.

Entonces, los tokens mencionados anteriormente equivaldr칤an, aproximadamente a:

||128K<br>(GPT-4o, GPT-4 Turbo, Llama)|200K<br>(o1, Claude)|1-2M<br>(Gemini 1.5)|
|-|:-:|:-:|:-:|
P치ginas de texto en Word<br>*(con tama침o de fuente est치ndar y m치rgenes normales)*|250-300|400-500|2000-4000
Palabras|~100.000|~160.000|~800.000 - 1.6M
Novelas completas<br>*considerando ~80.000 palabras por novela*|1-1.5 novelas|~2 novelas|10-20 novelas
Libros t칠cnicos/acad칠micos|2-3 libros est치ndar|3-4 libros|15-30 libros
Documentaci칩n completa de proyectos|Repositorio peque침o-mediano|Repositorio grande|M칰ltiples repositorios
[游늬](https://drive.google.com/drive/folders/1sHecgUKJyLfwhFBehn15R5bIXQTJ_sgs?usp=sharing) ***Pruebas de stress hist칩ricos***|游꿢 Capacidad suficiente para la mayor칤a de casos de uso pr치cticos|游꿢 Conversaciones extensas, an치lisis de m칰ltiples documentos|游꿢 An치lisis de bases de c칩digo completas, libros enteros

<details>
<summary><i>Equivalencias modelos anteriores</i></summary>

||4096<br>GPT-3.5|8192<br>GPT-4 (8K)|32768<br>GPT-4 (32K)|
|-|:-:|:-:|:-:|
P치ginas de texto en Word|8-10|16-20|65-80
Palabras|3500-4000|7000-8000|28000-32000
Tweets (280 caracteres)|15-20|30-40|120-160
Pruebas de stress|[游땻](https://chat.openai.com/share/6a42b7fd-59b4-475c-a818-af69c0fc5c61) [游땻游땻](https://chat.openai.com/share/e43be7f4-3e87-4ddd-800d-7606996eb203) [游땻游땻游땻](https://chat.openai.com/share/4396fda0-fe7f-43fc-8a43-28dc9e9d7d21) [游땻游땻游땻游땻](https://chat.openai.com/share/35492bb2-4252-4ab3-880c-b8792386ac51)|[游땻](https://chat.openai.com/share/b5fbcb0a-f57e-472f-99c6-8b831fbfb870) [游땻游땻游땻游땻](https://chat.openai.com/share/88efa50b-4c05-40b0-9c83-da7d6f477650)|*consciente* de limitaciones?

</details>

- [Trabajar con documentos](/documentos/casosDeUso/examenTipoTest.md), una forma de "mitigar" el problema con la ventana de contexto

> ***Actualizaci칩n:*** [Copilot ahora mantiene el contexto](https://copilot.microsoft.com/chats/FZif3PHfxRXSym3crGjsy) y lo [hace sorprendentemente bien!](https://drive.google.com/drive/folders/15NpyxP458Ct5b0pGa5f2Rx_6WEBHUmvP?usp=drive_link)

---

## 쯏 ahora qu칠?

<div align=right>

|Requisitos|Est치s en|Sigue...|
|-|-|-|
|[쯈u칠 son los prompts?](README.md)<br>Conceptos b치sicos|Fundamentos > Prompts > **Ventana de contexto**|[Tokens](tokens.md)<br>Unidades b치sicas de procesamiento
|[Modelos de lenguaje](../LLMs.md)<br>Funcionamiento de los LLMs||[Mejores pr치cticas](mejoresPracticas/README.md)<br>Optimizaci칩n considerando limitaciones

<i>**Relacionado**: [Repaso conversaciones](mejoresPracticas/repasoDeVezEnCuando.md) - Gesti칩n pr치ctica de l칤mites / [Resumen recursivo](mejoresPracticas/resumenDeResumen.md) - T칠cnica para documentos extensos / [Casos de uso](../casosDeUso/README.md) - Aplicaciones que consideran limitaciones</i>

</div>